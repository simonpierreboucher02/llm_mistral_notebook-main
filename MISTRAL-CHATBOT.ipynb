{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2cdac64-622f-4794-80f1-84bae314d46b",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    display: block;\n",
    "    padding: 12px 20px;\n",
    "    background-color: #1A73E8;\n",
    "    color: white;\n",
    "    border-radius: 30px;\n",
    "    font-family: 'Helvetica Neue', Arial, sans-serif;\n",
    "    font-size: 16px;\n",
    "    font-weight: 600;\n",
    "    margin: 15px auto;\n",
    "    width: fit-content;\n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
    "    text-align: center;\n",
    "    letter-spacing: 0.5px;\n",
    "\">\n",
    "    <strong>MISTRAL - CHATBOT</strong>\n",
    "</div>\n",
    "\n",
    "<div style=\"\n",
    "    display: block;\n",
    "    padding: 12px 20px;\n",
    "    background-color: #66BB6A;\n",
    "    color: white;\n",
    "    border-radius: 30px;\n",
    "    font-family: 'Helvetica Neue', Arial, sans-serif;\n",
    "    font-size: 16px;\n",
    "    font-weight: 600;\n",
    "    margin: 15px auto;\n",
    "    width: fit-content;\n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
    "    text-align: center;\n",
    "    letter-spacing: 0.5px;\n",
    "\">\n",
    "    <strong>Simon-Pierre Boucher</strong>\n",
    "</div>\n",
    "\n",
    "<div style=\"\n",
    "    display: block;\n",
    "    padding: 12px 20px;\n",
    "    background-color: #FFA726;\n",
    "    color: white;\n",
    "    border-radius: 30px;\n",
    "    font-family: 'Helvetica Neue', Arial, sans-serif;\n",
    "    font-size: 16px;\n",
    "    font-weight: 600;\n",
    "    margin: 15px auto;\n",
    "    width: fit-content;\n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
    "    text-align: center;\n",
    "    letter-spacing: 0.5px;\n",
    "\">\n",
    "    <strong>2024-09-14</strong>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07806c3-258c-4b0c-9c53-22beb1f37507",
   "metadata": {},
   "source": [
    "This code defines a **`ChatBot` class** that interacts with Mistral's API to generate conversational text responses. Here's a detailed summary of how the code works:\n",
    "\n",
    "### 1. **Environment Setup**:\n",
    "   - The environment variables are loaded from a `.env` file using `load_dotenv()`.\n",
    "   - The API key is fetched using `os.getenv(\"MISTRAL_API_KEY\")`.\n",
    "\n",
    "### 2. **`ChatBot` Class**:\n",
    "   - The `ChatBot` class is initialized with various parameters, including:\n",
    "     - **`api_key`**: The Mistral API key.\n",
    "     - **`model`**: The model to use for text generation (e.g., `codestral-mamba-latest` by default).\n",
    "     - **`temperature`** and **`top_p`**: Control randomness and diversity of the output.\n",
    "     - **`max_tokens`, `min_tokens`**: Set token limits for the generated response.\n",
    "     - **`tool_choice`, `safe_prompt`**: Options for tool integration and safety prompts.\n",
    "   - It keeps track of the conversation history in `self.conversation_history`, which is a list of all messages exchanged during the conversation.\n",
    "\n",
    "### 3. **Adding Messages**:\n",
    "   - The method `add_message()` appends a message to the conversation history with two parameters:\n",
    "     - **`role`**: Specifies who is sending the message (`\"user\"` or `\"assistant\"`).\n",
    "     - **`content`**: The actual text of the message.\n",
    "\n",
    "### 4. **Getting Responses**:\n",
    "   - The method `get_response()` takes the user input, adds it to the conversation history, and then calls the `generate_mistral_text()` method to get a response from the Mistral API.\n",
    "   - The response (the assistant's message) is extracted from the API result and added back to the conversation history.\n",
    "   - It then returns the assistant's reply to the user. If an error occurs during the API call, an error message is displayed.\n",
    "\n",
    "### 5. **Mistral Text Generation**:\n",
    "   - The `generate_mistral_text()` method sends a POST request to the Mistral API to generate a text response. It uses the following key parameters:\n",
    "     - **`model`**: The specific AI model to use.\n",
    "     - **`messages`**: A list of conversation messages (history), including both the user's inputs and previous assistant replies.\n",
    "     - **Optional settings**: Parameters like `temperature`, `top_p`, `max_tokens`, `stop`, `random_seed` allow customization of the response generation process.\n",
    "   - The API request is sent using the `requests.post()` method, with error handling to catch and print any request-related issues.\n",
    "\n",
    "### 6. **Example Usage**:\n",
    "   - A `ChatBot` instance is created with a specific model (`mistral-large-latest`) and the settings for text generation.\n",
    "   - The user input **\"Can you suggest 5 dinner ideas for this week?\"** is passed to the `get_response()` method.\n",
    "   - The bot generates a response, and it is printed.\n",
    "\n",
    "### Summary of Workflow:\n",
    "1. **User input** is received.\n",
    "2. **User message** is added to conversation history.\n",
    "3. **API request** is sent to Mistral with the entire conversation history.\n",
    "4. **Assistant's response** is extracted from the API's response.\n",
    "5. **Response** is added to the conversation history and printed.\n",
    "\n",
    "This implementation allows for dynamic, ongoing conversations with Mistral's text-generation API by maintaining a history of interactions and building context over multiple turns of dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0806ceb-057e-4ff6-8b18-0566dd166468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, HTML\n",
    "import re\n",
    "\n",
    "# Charger les variables d'environnement depuis le fichier .env\n",
    "load_dotenv()\n",
    "# Obtenir la clé API depuis les variables d'environnement\n",
    "api_key = os.getenv(\"MISTRAL_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a5560cf-3e9d-4af7-a033-b8d7027da106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class ChatBot:\n",
    "    def __init__(self, api_key, model=\"codestral-mamba-latest\", temperature=0.7, top_p=1.0, max_tokens=None, min_tokens=None, stream=False, stop=None, random_seed=None, tool_choice=\"auto\", safe_prompt=False):\n",
    "        \"\"\"\n",
    "        Initialize the ChatBot with API key and parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - api_key (str): The API key for Mistral.\n",
    "        - model (str): The model to use for text generation.\n",
    "        - temperature (float): Controls randomness in the output (0-1.5).\n",
    "        - top_p (float): Nucleus sampling (0-1).\n",
    "        - max_tokens (int): The maximum number of tokens to generate in the completion.\n",
    "        - min_tokens (int): The minimum number of tokens to generate in the completion.\n",
    "        - stream (bool): Whether to stream back partial progress.\n",
    "        - stop (str or list): Stop generation if this token or one of these tokens is detected.\n",
    "        - random_seed (int): The seed to use for random sampling.\n",
    "        - tool_choice (str): Tool choice for the response (\"auto\", \"none\", \"any\").\n",
    "        - safe_prompt (bool): Whether to inject a safety prompt before all conversations.\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "        self.max_tokens = max_tokens\n",
    "        self.min_tokens = min_tokens\n",
    "        self.stream = stream\n",
    "        self.stop = stop\n",
    "        self.random_seed = random_seed\n",
    "        self.tool_choice = tool_choice\n",
    "        self.safe_prompt = safe_prompt\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        \"\"\"\n",
    "        Add a message to the conversation history.\n",
    "        \n",
    "        Parameters:\n",
    "        - role (str): The role of the sender (\"system\", \"user\", or \"assistant\").\n",
    "        - content (str): The content of the message.\n",
    "        \"\"\"\n",
    "        self.conversation_history.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    def get_response(self, user_input):\n",
    "        \"\"\"\n",
    "        Get a response from the Mistral API based on the user input.\n",
    "        \n",
    "        Parameters:\n",
    "        - user_input (str): The user's input message.\n",
    "        \n",
    "        Returns:\n",
    "        - assistant_reply (str): The assistant's generated response.\n",
    "        \"\"\"\n",
    "        # Add user input to conversation history\n",
    "        self.add_message(\"user\", user_input)\n",
    "\n",
    "        # Call the Mistral API to get a response\n",
    "        response = self.generate_mistral_text(\n",
    "            self.api_key,\n",
    "            self.model,\n",
    "            self.conversation_history,\n",
    "            temperature=self.temperature,\n",
    "            top_p=self.top_p,\n",
    "            max_tokens=self.max_tokens,\n",
    "            min_tokens=self.min_tokens,\n",
    "            stream=self.stream,\n",
    "            stop=self.stop,\n",
    "            random_seed=self.random_seed,\n",
    "            tool_choice=self.tool_choice,\n",
    "            safe_prompt=self.safe_prompt\n",
    "        )\n",
    "\n",
    "        if response:\n",
    "            # Extract the assistant's reply\n",
    "            assistant_reply = response.get(\"choices\", [])[0].get(\"message\", {}).get(\"content\", \"No reply found.\")\n",
    "            # Add assistant's reply to conversation history\n",
    "            self.add_message(\"assistant\", assistant_reply)\n",
    "            return assistant_reply\n",
    "        else:\n",
    "            return \"Sorry, I couldn't generate a response.\"\n",
    "\n",
    "    def generate_mistral_text(self, api_key, model, messages, temperature=0.7, top_p=1.0, max_tokens=None, min_tokens=None, stream=False, stop=None, random_seed=None, tool_choice=\"auto\", safe_prompt=False):\n",
    "        \"\"\"\n",
    "        Generate text using Mistral's API.\n",
    "        \n",
    "        Parameters:\n",
    "        - api_key (str): The API key for Mistral.\n",
    "        - model (str): The model to use for text generation.\n",
    "        - messages (list): A list of messages to pass to the API in a conversation format.\n",
    "        - temperature (float): Controls randomness in the output (0-1.5).\n",
    "        - top_p (float): Nucleus sampling (0-1).\n",
    "        - max_tokens (int): The maximum number of tokens to generate in the completion.\n",
    "        - min_tokens (int): The minimum number of tokens to generate in the completion.\n",
    "        - stream (bool): Whether to stream back partial progress.\n",
    "        - stop (str or list): Stop generation if this token or one of these tokens is detected.\n",
    "        - random_seed (int): The seed to use for random sampling.\n",
    "        - tool_choice (str): Tool choice for the response (\"auto\", \"none\", \"any\").\n",
    "        - safe_prompt (bool): Whether to inject a safety prompt before all conversations.\n",
    "        \n",
    "        Returns:\n",
    "        - response (dict): The API response as a dictionary.\n",
    "        \"\"\"\n",
    "        url = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {api_key}\"\n",
    "        }\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"stream\": stream,\n",
    "            \"tool_choice\": tool_choice,\n",
    "            \"safe_prompt\": safe_prompt\n",
    "        }\n",
    "\n",
    "        # Optional parameters\n",
    "        if max_tokens is not None:\n",
    "            data[\"max_tokens\"] = max_tokens\n",
    "        if min_tokens is not None:\n",
    "            data[\"min_tokens\"] = min_tokens\n",
    "        if stop is not None:\n",
    "            data[\"stop\"] = stop\n",
    "        if random_seed is not None:\n",
    "            data[\"random_seed\"] = random_seed\n",
    "\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, json=data)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c800815c-8c74-4147-a2bd-e2e7045c167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = ChatBot(api_key, model=\"mistral-large-latest\", temperature=0.7, top_p=1.0, max_tokens=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f3e7f1a-7364-4f78-8fec-affac2129c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Absolutely, I'd be happy to help you plan your dinners for the week. Here are five dinner ideas that offer a mix of flavors and ease of preparation:\n",
      "\n",
      "1. **Monday - One-Pot Lemon Herb Chicken and Rice**\n",
      "   - Sauté chicken breasts in a large pot, then set them aside.\n",
      "   - In the same pot, cook rice with chicken broth, lemon zest, lemon juice, garlic, and herbs like thyme and rosemary.\n",
      "   - Once the rice is almost done, nestle the chicken back into the pot and let it finish cooking.\n",
      "\n",
      "2. **Tuesday - Vegetarian Stuffed Bell Peppers**\n",
      "   - Halve bell peppers lengthwise and remove seeds.\n",
      "   - Fill them with a mixture of cooked quinoa, black beans, corn, diced tomatoes, onion, and your choice of seasoning.\n",
      "   - Bake until the peppers are tender and serve with a side salad.\n",
      "\n",
      "3. **Wednesday - Baked Salmon with Asparagus**\n",
      "   - Place salmon fillets on a baking sheet, season with salt, pepper, lemon slices, and dill.\n",
      "   - Toss asparagus with olive oil, salt, and pepper, and arrange them around the salmon.\n",
      "   - Bake until the salmon is cooked through and the asparagus is tender.\n",
      "\n",
      "4. **Thursday - Easy Bolognese with Pasta**\n",
      "   - Brown some ground beef or turkey in a pan, then add onions, garlic, and carrots.\n",
      "   - Stir in canned tomatoes, tomato paste, and Italian seasoning. Let it simmer.\n",
      "   - Serve over your favorite pasta with a side of garlic bread.\n",
      "\n",
      "5. **Friday - Sheet Pan Fajitas**\n",
      "   - Slice bell peppers, onions, and chicken breast. Toss them with olive oil, fajita seasoning, salt, and pepper.\n",
      "   - Spread the mixture evenly on a sheet pan and bake until the chicken is cooked through and the vegetables are tender.\n",
      "   - Serve with warm tortillas, sour cream, guacamole, and fresh salsa.\n",
      "\n",
      "Enjoy your week of meals! Remember, you can always adjust these ideas based on your dietary needs and preferences.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Can you suggest 5 dinner ideas for this week?\"\n",
    "response = bot.get_response(user_input)\n",
    "print(\"Assistant:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51769381-0dc9-4742-9b72-3fc8bb49d6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Certainly! Here's a more detailed recipe for the One-Pot Lemon Herb Chicken and Rice:\n",
      "\n",
      "**Ingredients:**\n",
      "\n",
      "* 4 boneless, skinless chicken breasts\n",
      "* Salt and pepper, to taste\n",
      "* 2 tbsp olive oil\n",
      "* 1 small onion, finely chopped\n",
      "* 2 cloves garlic, minced\n",
      "* 1 cup uncooked long-grain white rice\n",
      "* 2 cups low-sodium chicken broth\n",
      "* Zest and juice of 1 lemon\n",
      "* 1 tsp dried thyme (or 1 tbsp fresh thyme leaves)\n",
      "* 1 tsp dried rosemary (or 1 tbsp fresh rosemary, finely chopped)\n",
      "* 1 bay leaf\n",
      "* Fresh parsley, chopped (for garnish)\n",
      "\n",
      "**Instructions:**\n",
      "\n",
      "1. **Season the chicken:** Pat the chicken breasts dry with paper towels and season both sides with salt and pepper.\n",
      "\n",
      "2. **Sauté the chicken:** Heat the olive oil in a large, deep skillet or Dutch oven over medium-high heat. Add the chicken breasts and cook until browned, about 5-7 minutes per side. Remove the chicken from the skillet and set it aside.\n",
      "\n",
      "3. **Cook the onion and garlic:** In the same skillet, add the chopped onion and cook until softened, about 5 minutes. Add the minced garlic and cook for an additional 1 minute, stirring frequently to prevent burning.\n",
      "\n",
      "4. **Add the rice and herbs:** Stir in the uncooked rice, chicken broth, lemon zest, lemon juice, thyme, rosemary, and bay leaf. Bring the mixture to a boil.\n",
      "\n",
      "5. **Cook the rice:** Once boiling, reduce the heat to low, cover the skillet, and let the rice simmer for about 15 minutes, or until most of the liquid has been absorbed and the rice is almost cooked.\n",
      "\n",
      "6. **Add the chicken back in:** Nestle the chicken breasts back into the skillet, on top of the rice. Spoon some of the rice and liquid over the chicken. Cover the skillet again and cook for an additional 15-20 minutes, or until the chicken is cooked through and the rice is tender.\n",
      "\n",
      "7. **Rest and serve:** Remove the skillet from the heat and let the dish rest, covered, for 10 minutes. This will allow the flavors to meld and the liquid to distribute evenly. Garnish with chopped fresh parsley before serving.\n",
      "\n",
      "Enjoy your One-Pot Lemon Herb Chicken and Rice! This dish pairs well with a side of steamed vegetables or a simple green salad.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Can you give me the recipe for the first idea?\"\n",
    "response = bot.get_response(user_input)\n",
    "print(\"Assistant:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f2aac46-9c1b-4862-b3c4-a9b619140d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Of course! Here's a detailed recipe for the Vegetarian Stuffed Bell Peppers:\n",
      "\n",
      "**Ingredients:**\n",
      "\n",
      "* 4 large bell peppers, any color, halved lengthwise and seeds removed\n",
      "* 1 cup cooked quinoa\n",
      "* 1 can (15 oz) black beans, drained and rinsed\n",
      "* 1 cup frozen corn, thawed\n",
      "* 1 cup diced tomatoes (canned or fresh)\n",
      "* ½ small onion, finely chopped\n",
      "* 2 cloves garlic, minced\n",
      "* 1 tsp ground cumin\n",
      "* 1 tsp chili powder\n",
      "* ½ tsp smoked paprika (optional)\n",
      "* Salt and pepper, to taste\n",
      "* 1 cup shredded cheese (e.g., cheddar, Monterey Jack, or Mexican blend), plus extra for topping\n",
      "* 2 tbsp olive oil\n",
      "* 2 tbsp fresh cilantro, chopped (for garnish)\n",
      "* Optional toppings: sour cream, Greek yogurt, avocado, or guacamole\n",
      "\n",
      "**Instructions:**\n",
      "\n",
      "1. **Preheat the oven:** Preheat your oven to 375°F (190°C) and lightly grease a baking dish large enough to hold the bell pepper halves.\n",
      "\n",
      "2. **Prepare the filling:** In a large bowl, combine the cooked quinoa, black beans, corn, diced tomatoes, chopped onion, minced garlic, cumin, chili powder, smoked paprika (if using), salt, and pepper. Mix well to combine. Stir in the shredded cheese.\n",
      "\n",
      "3. **Stuff the bell peppers:** Place the bell pepper halves in the prepared baking dish, cut side up. Spoon the quinoa and bean mixture evenly into each pepper half, pressing down gently to compact the filling.\n",
      "\n",
      "4. **Bake:** Drizzle the olive oil over the stuffed peppers and cover the baking dish with foil. Bake for 30 minutes. Remove the foil, sprinkle additional shredded cheese on top of each pepper, and bake for an additional 10-15 minutes, or until the peppers are tender and the cheese is melted and golden.\n",
      "\n",
      "5. **Serve:** Let the stuffed bell peppers cool for a few minutes before serving. Garnish with chopped fresh cilantro and your choice of optional toppings, such as sour cream, Greek yogurt, avocado, or guacamole.\n",
      "\n",
      "Enjoy your Vegetarian Stuffed Bell Peppers! You can serve them with a side salad or some crusty bread to complete the meal.\n",
      "\n",
      "**Tip:** To make this dish vegan, simply omit the cheese or use a plant-based cheese alternative. You can also customize the filling ingredients based on your preferences or what you have on hand.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Can you give me the recipe for the second idea?\"\n",
    "response = bot.get_response(user_input)\n",
    "print(\"Assistant:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
